{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897, 21) (897, 1) (100, 21) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# 按列标准化\n",
    "def normalization(data):\n",
    "    min_vals = np.min(data, axis=0)\n",
    "    max_vals = np.max(data, axis=0)\n",
    "    _range = max_vals - min_vals\n",
    "    return (data - min_vals) / _range\n",
    "\n",
    "# 加载数据\n",
    "original_data = pd.read_csv('./datasets/AEEEM/JDT.csv')       \n",
    "\n",
    "original_data.isnull().values.any()  # Gives false ie:No null value in dataset\n",
    "original_data = original_data.fillna(value=False)  #将缺失值填充为False\n",
    "original_Y = original_data['class']  # Defective   class   isDefective  defects  label\n",
    "original_Y = pd.DataFrame(original_Y)    \n",
    "original_data = normalization(original_data)    \n",
    "\n",
    "original_X = pd.DataFrame(original_data.drop(['class'], axis=1))  \n",
    "\n",
    "#分为训练集和测试集  \n",
    "x_train, x_test, y_train, y_test = train_test_split(original_X, original_Y, test_size=.1, random_state=12)\n",
    "print(x_train.shape, y_train.shape,x_test.shape, y_test.shape)\n",
    "sm = SMOTE(random_state=12, sampling_strategy=1.0)  # 解决分类不平衡问题\n",
    "x, y = sm.fit_resample(x_train, y_train)  \n",
    "y_train = pd.DataFrame(y, columns=['class'])    #Defective  class  isDefective  defects\n",
    "x_train = pd.DataFrame(x, columns=original_X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#细分出验证集\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.1, random_state=12)\n",
    "\n",
    "x_train = x_train.values\n",
    "x_val = x_val.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# 将数据重塑为适合一维卷积的格式\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "# print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1276, 2) (142, 2) (100, 2)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "\n",
    "# 将标签转换为独热编码向量\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将输入数据转变为浮点型\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_val = x_val.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (21, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape  = (x_train.shape[1], 1)\n",
    "\n",
    "print(f'input_shape: {input_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/xgf/Disstill_defect_interpretation/Disstill_defect_interpretation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/user/xgf/Disstill_defect_interpretation/Disstill_defect_interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.convnet import ConvNet\n",
    "from models.tree import SoftDecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ConvNet(input_shape, n_classes=n_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_soft = nn.predict(x_train)\n",
    "# y_train_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1276, 21), (142, 21), (100, 21))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先将数据展平，变成二维数据\n",
    "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
    "x_val_flat = x_val.reshape((x_val.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "x_train_flat.shape, x_val_flat.shape, x_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 参数设置\n",
    "max_depth = 4\n",
    "n_features = x_train.shape[1]\n",
    "n_classes = 2\n",
    "penalty_strength = 1e+1\n",
    "penalty_decay = 0.25\n",
    "inv_temp = 0.01  # 逆温度参数\n",
    "epochs = 40\n",
    "ema_win_size = 100\n",
    " \n",
    "\n",
    "# 解释器模型 g_model\n",
    "g_model = SoftDecisionTree(max_depth=max_depth, n_features=n_features, n_classes=n_classes, \n",
    "                          penalty_strength=penalty_strength, penalty_decay=penalty_decay, \n",
    "                          inv_temp=inv_temp, ema_win_size=ema_win_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joint import analyze, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.5726 - loss_g: 5.4713 - accuracy_f: 0.6819 - accuracy_g: 0.5409\n",
      "Epoch 2/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4910 - loss_g: 5.2660 - accuracy_f: 0.7356 - accuracy_g: 0.5635\n",
      "Epoch 3/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4754 - loss_g: 5.1182 - accuracy_f: 0.7501 - accuracy_g: 0.6066\n",
      "Epoch 4/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4466 - loss_g: 5.0013 - accuracy_f: 0.7595 - accuracy_g: 0.6414\n",
      "Epoch 5/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4603 - loss_g: 4.9018 - accuracy_f: 0.7654 - accuracy_g: 0.6660\n",
      "Epoch 6/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4592 - loss_g: 4.8163 - accuracy_f: 0.7701 - accuracy_g: 0.6855\n",
      "Epoch 7/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4606 - loss_g: 4.7388 - accuracy_f: 0.7716 - accuracy_g: 0.6980\n",
      "Epoch 8/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4440 - loss_g: 4.6706 - accuracy_f: 0.7745 - accuracy_g: 0.7073\n",
      "Epoch 9/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4359 - loss_g: 4.6086 - accuracy_f: 0.7766 - accuracy_g: 0.7141\n",
      "Epoch 10/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4377 - loss_g: 4.5525 - accuracy_f: 0.7790 - accuracy_g: 0.7188\n",
      "Epoch 11/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4269 - loss_g: 4.5011 - accuracy_f: 0.7821 - accuracy_g: 0.7242\n",
      "Epoch 12/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4361 - loss_g: 4.4537 - accuracy_f: 0.7832 - accuracy_g: 0.7278\n",
      "Epoch 13/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4320 - loss_g: 4.4098 - accuracy_f: 0.7854 - accuracy_g: 0.7312\n",
      "Epoch 14/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4107 - loss_g: 4.3700 - accuracy_f: 0.7880 - accuracy_g: 0.7348\n",
      "Epoch 15/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4285 - loss_g: 4.3320 - accuracy_f: 0.7897 - accuracy_g: 0.7378\n",
      "Epoch 16/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4161 - loss_g: 4.2971 - accuracy_f: 0.7911 - accuracy_g: 0.7402\n",
      "Epoch 17/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4030 - loss_g: 4.2644 - accuracy_f: 0.7934 - accuracy_g: 0.7433\n",
      "Epoch 18/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4090 - loss_g: 4.2332 - accuracy_f: 0.7947 - accuracy_g: 0.7450\n",
      "Epoch 19/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4084 - loss_g: 4.2055 - accuracy_f: 0.7960 - accuracy_g: 0.7469\n",
      "Epoch 20/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4237 - loss_g: 4.1789 - accuracy_f: 0.7974 - accuracy_g: 0.7484\n",
      "Epoch 21/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4175 - loss_g: 4.1549 - accuracy_f: 0.7984 - accuracy_g: 0.7504\n",
      "Epoch 22/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4050 - loss_g: 4.1317 - accuracy_f: 0.7994 - accuracy_g: 0.7519\n",
      "Epoch 23/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.3994 - loss_g: 4.1092 - accuracy_f: 0.8005 - accuracy_g: 0.7533\n",
      "Epoch 24/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4115 - loss_g: 4.0880 - accuracy_f: 0.8013 - accuracy_g: 0.7544\n",
      "Epoch 25/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4059 - loss_g: 4.0690 - accuracy_f: 0.8022 - accuracy_g: 0.7558\n",
      "Epoch 26/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4046 - loss_g: 4.0503 - accuracy_f: 0.8024 - accuracy_g: 0.7566\n",
      "Epoch 27/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4096 - loss_g: 4.0340 - accuracy_f: 0.8032 - accuracy_g: 0.7579\n",
      "Epoch 28/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.3841 - loss_g: 4.0163 - accuracy_f: 0.8040 - accuracy_g: 0.7586\n",
      "Epoch 29/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.3965 - loss_g: 4.0002 - accuracy_f: 0.8047 - accuracy_g: 0.7594\n",
      "Epoch 30/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.3955 - loss_g: 3.9855 - accuracy_f: 0.8053 - accuracy_g: 0.7604\n",
      "Epoch 31/40\n",
      "1276/1276 [==============================] - 14s 11ms/samples - loss_f: 0.4474 - loss_g: 3.9708 - accuracy_f: 0.8057 - accuracy_g: 0.7610\n",
      "Epoch 32/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4617 - loss_g: 3.9573 - accuracy_f: 0.8053 - accuracy_g: 0.7618\n",
      "Epoch 33/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4235 - loss_g: 3.9445 - accuracy_f: 0.8052 - accuracy_g: 0.7625\n",
      "Epoch 34/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4117 - loss_g: 3.9317 - accuracy_f: 0.8057 - accuracy_g: 0.7631\n",
      "Epoch 35/40\n",
      "1276/1276 [==============================] - 14s 11ms/samples - loss_f: 0.3811 - loss_g: 3.9203 - accuracy_f: 0.8062 - accuracy_g: 0.7638\n",
      "Epoch 36/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4670 - loss_g: 3.9092 - accuracy_f: 0.8065 - accuracy_g: 0.7641\n",
      "Epoch 37/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4598 - loss_g: 3.8978 - accuracy_f: 0.8059 - accuracy_g: 0.7649\n",
      "Epoch 38/40\n",
      "1276/1276 [==============================] - 14s 11ms/samples - loss_f: 0.4127 - loss_g: 3.8874 - accuracy_f: 0.8058 - accuracy_g: 0.7651\n",
      "Epoch 39/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4557 - loss_g: 3.8774 - accuracy_f: 0.8060 - accuracy_g: 0.7659\n",
      "Epoch 40/40\n",
      "1276/1276 [==============================] - 13s 10ms/samples - loss_f: 0.4554 - loss_g: 3.8676 - accuracy_f: 0.8055 - accuracy_g: 0.7662\n"
     ]
    }
   ],
   "source": [
    "epochs = 40 \n",
    "batch_size = 16  \n",
    "\n",
    "# 设置模型保存的路径\n",
    "f_model_path = 'assets/JDT/f_model_joint'\n",
    "g_model_path = 'assets/JDT/g_model_joint'\n",
    "\n",
    "# 检查模型文件是否存在\n",
    "f_model_exists = os.path.exists(f_model_path + \".index\")\n",
    "g_model_exists = os.path.exists(g_model_path + \".index\")\n",
    "\n",
    "data_test = (x_test, x_test_flat, y_test)\n",
    "data_val = (x_val, x_val_flat, y_val)\n",
    "\n",
    "if not f_model_exists or not g_model_exists:\n",
    "    # 如果模型文件不存在，则训练模型\n",
    "    f_model_joint, g_model_joint = train(nn, g_model, x_train, x_train_flat, y_train, data_val, epochs, batch_size=batch_size)\n",
    "    # save model\n",
    "    f_model_joint.save_weights(f_model_path)\n",
    "    g_model_joint.save_weights(g_model_path)\n",
    "    \n",
    "\n",
    "else:\n",
    "    # g_model\n",
    "    g_model_joint = SoftDecisionTree(max_depth=max_depth, n_features=n_features, n_classes=n_classes, \n",
    "                          penalty_strength=penalty_strength, penalty_decay=penalty_decay, \n",
    "                          inv_temp=inv_temp, ema_win_size=ema_win_size)\n",
    "    # f_model\n",
    "    f_model_joint = ConvNet(input_shape, n_classes=n_classes)  \n",
    "\n",
    "    # load model\n",
    "    f_model_joint.load_weights(f_model_path)\n",
    "    g_model_joint.load_weights(g_model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joint import analyze\n",
    "\n",
    "# 计算保真度\n",
    "f_joint_acc, fidelity, g_joint_acc = analyze(f_model_joint, g_model_joint, x_test, x_test_flat, y_test)\n",
    "\n",
    "print(\"Accuracy of f (in %): {:.2f}\".format(f_joint_acc * 100))\n",
    "print(\"Accuracy of g (in %): {:.2f}\".format(g_joint_acc * 100))\n",
    "print(\"Fidelity (in %): {:.2f}\".format(fidelity * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算其他指标（MCC、AUC、F1-score）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = f_model_joint.predict(x_test)\n",
    "y_pred_ = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy_score=metrics.accuracy_score(y_test_,y_pred_)\n",
    "\n",
    "print(f\"accuracy_score={accuracy_score: .4f}\")\n",
    "\n",
    "fscore=metrics.f1_score(y_test_,y_pred_,average='macro')\n",
    "print(f\"f-score={fscore: .4f}\")\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test_, y_pred_, average='macro')\n",
    "print(f\"auc={auc: .4f}\")\n",
    "\n",
    "mcc = metrics.matthews_corrcoef(y_test_, y_pred_)\n",
    "print(f\"MCC={mcc: .4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
