{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    min_vals = np.min(data, axis=0)\n",
    "    max_vals = np.max(data, axis=0)\n",
    "    _range = max_vals - min_vals\n",
    "    return (data - min_vals) / _range\n",
    "\n",
    "original_data = pd.read_csv('./datasets/NASA/kc1.csv')       \n",
    "\n",
    "original_data.isnull().values.any()  # Gives false ie:No null value in dataset\n",
    "original_data = original_data.fillna(value=False)  \n",
    "original_Y = original_data['defects']  \n",
    "original_Y = pd.DataFrame(original_Y)    \n",
    "original_data = normalization(original_data)    \n",
    "\n",
    "original_X = pd.DataFrame(original_data.drop(['defects'], axis=1))  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(original_X, original_Y, test_size=.1, random_state=12)\n",
    "print(x_train.shape, y_train.shape,x_test.shape, y_test.shape)\n",
    "sm = SMOTE(random_state=12, sampling_strategy=1.0)  \n",
    "x, y = sm.fit_resample(x_train, y_train)  \n",
    "y_train = pd.DataFrame(y, columns=['defects'])    \n",
    "x_train = pd.DataFrame(x, columns=original_X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.1, random_state=12)\n",
    "\n",
    "x_train = x_train.values\n",
    "x_val = x_val.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "# print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2899, 2) (323, 2) (211, 2)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_val = x_val.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (21, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape  = (x_train.shape[1], 1)\n",
    "\n",
    "print(f'input_shape: {input_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.convnet import ConvNet\n",
    "from models.tree import SoftDecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ConvNet(input_shape, n_classes=n_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_soft = nn.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2899, 21), (323, 21), (211, 21))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
    "x_val_flat = x_val.reshape((x_val.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "\n",
    "\n",
    "x_train_flat.shape, x_val_flat.shape, x_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 4\n",
    "n_features = x_train.shape[1]\n",
    "n_classes = 2\n",
    "penalty_strength = 1e+1\n",
    "penalty_decay = 0.25\n",
    "inv_temp = 0.01  \n",
    "epochs = 40\n",
    "ema_win_size = 100\n",
    " \n",
    "g_model = SoftDecisionTree(max_depth=max_depth, n_features=n_features, n_classes=n_classes, \n",
    "                          penalty_strength=penalty_strength, penalty_decay=penalty_decay, \n",
    "                          inv_temp=inv_temp, ema_win_size=ema_win_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joint import analyze, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40 \n",
    "batch_size = 32  \n",
    "\n",
    "f_model_path = 'assets/kc1/f_model_joint'\n",
    "g_model_path = 'assets/kc1/g_model_joint'\n",
    "\n",
    "f_model_exists = os.path.exists(f_model_path + \".index\")\n",
    "g_model_exists = os.path.exists(g_model_path + \".index\")\n",
    "\n",
    "data_test = (x_test, x_test_flat, y_test)\n",
    "data_val = (x_val, x_val_flat, y_val)\n",
    "\n",
    "if not f_model_exists or not g_model_exists:\n",
    "    f_model_joint, g_model_joint = train(nn, g_model, x_train, x_train_flat, y_train, data_val, epochs, batch_size=batch_size)\n",
    "    \n",
    "    f_model_joint.save_weights(f_model_path)\n",
    "    g_model_joint.save_weights(g_model_path)\n",
    "    \n",
    "\n",
    "else:\n",
    "    g_model_joint = SoftDecisionTree(max_depth=max_depth, n_features=n_features, n_classes=n_classes, \n",
    "                          penalty_strength=penalty_strength, penalty_decay=penalty_decay, \n",
    "                          inv_temp=inv_temp, ema_win_size=ema_win_size)\n",
    "    f_model_joint = ConvNet(input_shape, n_classes=n_classes)  \n",
    "\n",
    "    f_model_joint.load_weights(f_model_path)\n",
    "    g_model_joint.load_weights(g_model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joint import analyze\n",
    "\n",
    "f_joint_acc, fidelity, g_joint_acc = analyze(f_model_joint, g_model_joint, x_test, x_test_flat, y_test)\n",
    "\n",
    "print(\"Accuracy of f (in %): {:.2f}\".format(f_joint_acc * 100))\n",
    "print(\"Accuracy of g (in %): {:.2f}\".format(g_joint_acc * 100))\n",
    "print(\"Fidelity (in %): {:.2f}\".format(fidelity * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算其他指标（MCC、AUC、F1-score）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
